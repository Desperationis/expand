#!/bin/python3
import os
import sys
import hashlib
from concurrent.futures import ThreadPoolExecutor

def generate_checksums(directory, workers):
    """Generate a set of checksums for all files in a directory using multithreading."""
    checksums = set()
    
    def process_file(filepath):
        """Calculate the checksum of a single file."""
        with open(filepath, 'rb') as f:
            file_hash = hashlib.md5()
            while chunk := f.read(8192):
                file_hash.update(chunk)
            return file_hash.hexdigest()

    def worker(filepath):
        print(f"Getting checksum of {file}")
        return process_file(filepath)

    # Collect all file paths
    file_paths = []
    for root, _, files in os.walk(directory):
        for file in files:
            file_paths.append(os.path.join(root, file))

    # Use ThreadPoolExecutor to process files concurrently
    with ThreadPoolExecutor(max_workers=workers) as executor:
        for checksum in executor.map(worker, file_paths):
            checksums.add(checksum)

    return checksums

def compare_directories(dir1, dir2, workers):
    """Compare two directories based on file checksums."""
    checksums1 = generate_checksums(dir1, workers)
    checksums2 = generate_checksums(dir2, workers)

    print("Checking if all checksums match and exist...")
    if checksums1 == checksums2:
        print("The directories contain the same files.")
    else:
        print("The directories do not contain the same files.")
        print(f"Files unique to {dir1}: {len(checksums1 - checksums2)}")
        print(f"Files unique to {dir2}: {len(checksums2 - checksums1)}")

if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("Usage: python script.py <directory1> <directory2> <workers>")
        sys.exit(1)

    dir1, dir2, workers = sys.argv[1], sys.argv[2], int(sys.argv[3])
    compare_directories(dir1, dir2, workers)

